# LLM-Semantic-Analysis-DV
Methodology for Analyzing Large Language Models

This repository presents a methodology for analyzing large language models (LLMs) based on Moral Foundations Theory (MFT). The approach enables the identification of knowledge gaps and sources of hallucinations in LLMs.

A classification system was developed using vector representations that capture differentiating values employed to polarize opposing stances. The methodology was validated on corpora of political and health-related texts (with a focus on vaccination discourse), applying:

Multidimensional Scaling (MDS)

Support Vector Machines (SVM)

Key Findings

OpenAI Embeddings (text-embedding-3-large) dominated in health-related text classification.

Gemini Embedding (gemini-embedding-exp-03-07) achieved the highest F1 score in the political domain.

Generative models demonstrated specialization:

Mistral 0.1 performed best on health texts.

LLaMA 3.1 excelled in political text classification.

Contributions

Introduced the concept of polarization criteria as a new evaluation tool for LLMs.

Proposed a theoretical extension to MFT.

Complemented standard benchmarks by highlighting knowledge deficiencies in both LLMs and embedding models.
